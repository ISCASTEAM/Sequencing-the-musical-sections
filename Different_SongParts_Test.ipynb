{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this file combare the result between SEN_model and Triplet_LSTM_model\n",
    "# by using different SongParts which filted form [3,10] in the sameSong\n",
    "# remeber to normalize the song part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "from random import randint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#randome filter the song in such parts\n",
    "songPart = [3,4,5,6,7,8,9,10]\n",
    "#when part=10，the orderation is very big. \n",
    "#so wo test 100 song rather than more than 100song. the premutaion is 100*(10*9*8) pairs\n",
    "sample = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(3)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SEN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.siamese_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, kernel_size=[4,128],stride=[1,128]),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=[4,1],stride=[1,1]),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=[4,1],stride=[1,1]),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.late_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=[3,3],stride=[1,1]),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=[3,3],stride=[3,3],padding=1),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=[3,3],stride=[1,1]),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=[3,3],stride=[3,3],padding=[1,0]),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=[3,3],stride=[1,1]),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.fcWithDropout = nn.Sequential(\n",
    "            nn.Linear(768, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            \n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            \n",
    "            nn.Linear(1024, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "            )\n",
    "    def cal_similarity(self,matrix1,matrix2):\n",
    "        out1 = torch.squeeze(matrix1,dim=3)\n",
    "        out2 = torch.squeeze(matrix2,dim=3)\n",
    "        num = torch.bmm(torch.transpose(out1,1,2),out2)\n",
    "        h1_norm = torch.sqrt(torch.sum(torch.mul(out1,out1), dim=1, keepdim=True))\n",
    "        h2_norm = torch.sqrt(torch.sum(torch.mul(out2,out2), dim=1, keepdim=True))\n",
    "        denom = torch.bmm(torch.transpose(h1_norm,1,2),h2_norm)\n",
    "        fms = torch.unsqueeze(torch.div(num,denom),dim=1)\n",
    "        return fms\n",
    "    \n",
    "    def _reduce_var(self,inputs):\n",
    "        m1 = torch.mean(inputs,dim=2,keepdim=True)\n",
    "        m = torch.mean(m1,dim=3,keepdim=True)\n",
    "        devs_squared1 = torch.mul(inputs - m,inputs - m)\n",
    "        devs_squared2 = torch.mean(devs_squared1,dim=2)\n",
    "        devs_squared = torch.mean(devs_squared2,dim=2)\n",
    "        return devs_squared\n",
    "\n",
    "    def cal_global_pool(self,matrix):\n",
    "        g_max1,_ = torch.max(matrix,dim=2)\n",
    "        g_max,_ = torch.max(g_max1,dim=2)\n",
    "        g_mean1 = torch.mean(matrix,dim=2)\n",
    "        g_mean = torch.mean(g_mean1,dim=2)\n",
    "        g_var = self._reduce_var(matrix)\n",
    "        return torch.cat([g_max, g_mean, g_var], 1)\n",
    "        \n",
    "    def forward(self,x1,x2):\n",
    "        out1 = self.siamese_cnn(x1)\n",
    "        out2 = self.siamese_cnn(x2)\n",
    "        similarity = self.cal_similarity(out1,out2)\n",
    "        late_cnn_out = self.late_cnn(similarity)\n",
    "        golbal_pool_out = self.cal_global_pool(late_cnn_out)\n",
    "        predictions = self.fcWithDropout(golbal_pool_out)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TripletLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.siamese_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, kernel_size=[4,128],stride=[1,128]),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=[4,1],stride=[1,1]),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=[4,1],stride=[1,1]),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        #max_pool need keep input.shape=output.shape\n",
    "        self.late_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=[3,3],stride=[1,1]),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=[3,3],stride=[3,3],padding=1),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=[3,3],stride=[1,1]),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=[3,3],stride=[3,3],padding=[1,0]),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=[3,3],stride=[1,1]),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.fcWithDropout = nn.Sequential(\n",
    "            nn.Linear(256, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "\n",
    "            nn.Linear(1024, 2),\n",
    "            nn.Softmax(dim=1),\n",
    "            )\n",
    "        self.rnnLSTM = nn.LSTM(\n",
    "            input_size=256, \n",
    "            hidden_size=128,\n",
    "            num_layers=2,\n",
    "            dropout=0.1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            )\n",
    "        \n",
    "    def cal_similarity(self,matrix1,matrix2):\n",
    "        out1 = torch.squeeze(matrix1,dim=3)\n",
    "        out2 = torch.squeeze(matrix2,dim=3)\n",
    "        num = torch.bmm(torch.transpose(out1,1,2),out2)\n",
    "        h1_norm = torch.sqrt(torch.sum(torch.mul(out1,out1), dim=1, keepdim=True))\n",
    "        h2_norm = torch.sqrt(torch.sum(torch.mul(out2,out2), dim=1, keepdim=True))\n",
    "        denom = torch.bmm(torch.transpose(h1_norm,1,2),h2_norm)\n",
    "        fms = torch.unsqueeze(torch.div(num,denom),dim=1)\n",
    "        return fms\n",
    "    \n",
    "    def _reduce_var(self,inputs):\n",
    "        m1 = torch.mean(inputs,dim=2,keepdim=True)\n",
    "        m = torch.mean(m1,dim=3,keepdim=True)\n",
    "        devs_squared1 = torch.mul(inputs - m,inputs - m)\n",
    "        devs_squared2 = torch.mean(devs_squared1,dim=2)\n",
    "        devs_squared = torch.mean(devs_squared2,dim=2)\n",
    "        return devs_squared\n",
    "    \n",
    "    def cal_global_pool(self,matrix):\n",
    "        g_max1,_ = torch.max(matrix,dim=2)\n",
    "        g_max,_ = torch.max(g_max1,dim=2)\n",
    "        g_mean1 = torch.mean(matrix,dim=2)\n",
    "        g_mean = torch.mean(g_mean1,dim=2)\n",
    "        g_var = self._reduce_var(matrix)\n",
    "        return torch.cat([g_max, g_mean, g_var], 1)\n",
    "    \n",
    "    def cal_lstm(self,seqInput):\n",
    "        #view batchsize seq-length input-size\n",
    "        #dataParaller may change the batchsize\n",
    "        lstm_batchSize = list(seqInput.size())[0]\n",
    "        seqInput = seqInput.view(lstm_batchSize,3,-1)\n",
    "        outLstm,(_,_) = self.rnnLSTM(seqInput)\n",
    "        return outLstm[:,-1,:]\n",
    "        \n",
    "    def forward(self,x1,x2,x3):\n",
    "        out1 = self.siamese_cnn(x1)\n",
    "        out2 = self.siamese_cnn(x2)\n",
    "        out3 = self.siamese_cnn(x2)\n",
    "        out4 = self.siamese_cnn(x3)\n",
    "        similarity1 = self.cal_similarity(out1,out2)\n",
    "        similarity2 = self.cal_similarity(out3,out4)\n",
    "        late_cnn_out = self.late_cnn((similarity1 + similarity2)/2)\n",
    "        golbal_pool_out = self.cal_global_pool(late_cnn_out)\n",
    "        lstmout = self.cal_lstm(golbal_pool_out)\n",
    "        predictions = self.fcWithDropout(lstmout)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72000\n",
      "72000\n"
     ]
    }
   ],
   "source": [
    "tripleNet_LSTM_model = TripletLSTM().double().cuda()\n",
    "state_dict = torch.load('./model/tripleNet_LSTM.pkl',map_location={'cuda:0':'cuda:3'})\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] \n",
    "    new_state_dict[name] = v\n",
    "tripleNet_LSTM_model.load_state_dict(new_state_dict)\n",
    "tripleNet_LSTM_model = tripleNet_LSTM_model.eval()\n",
    "\n",
    "#test about 100 songs in 10 part ，so later we use in different parts test\n",
    "#100*10*9*8\n",
    "LSTM_testdata = []\n",
    "LSTM_testlabel = []\n",
    "\n",
    "#所有的triplet的总数   1000*10*9*8\n",
    "for song in range(sample):\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            for k in range(10):\n",
    "                if(i != j and j != k and i !=k):\n",
    "                    triplet = \"song{}_{},song{}_{},song{}_{}\".format(song,i,song,j,song,k)\n",
    "                    LSTM_testdata.append(triplet)\n",
    "                if(j-i==1 and k-j==1):\n",
    "                    LSTM_testlabel.append(0)\n",
    "                elif(i != j and j != k and i !=k):\n",
    "                    LSTM_testlabel.append(1)\n",
    "                    \n",
    "print(len(LSTM_testdata))\n",
    "print(len(LSTM_testlabel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "SENmodel = SEN().double().cuda()\n",
    "state_dict = torch.load('./model/baseline_sen.pkl',map_location={'cuda:2':'cuda:3'})\n",
    "SENmodel.load_state_dict(state_dict)\n",
    "SENmodel = SENmodel.eval()\n",
    "\n",
    "#test about 100 songs in 10 part ，so later we use in different parts test\n",
    "#100*10*9\n",
    "SEN_testdata = []\n",
    "SEN_testlabel = []\n",
    "\n",
    "for song in range(sample):\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "                if(i != j):\n",
    "                    test_pair = \"song{}_{},song{}_{}\".format(song,i,song,j)\n",
    "                    SEN_testdata.append(test_pair)\n",
    "                if(j-i==1):\n",
    "                    SEN_testlabel.append(0)\n",
    "                elif(i != j):\n",
    "                    SEN_testlabel.append(1)\n",
    "print(len(SEN_testdata))\n",
    "print(len(SEN_testlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72000\n",
      "72000\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/media/data/cuixuange/ScrawlMusic/train_data_10part_normalizatin/\"\n",
    "def load_exits_file(train_data,index):\n",
    "    str_data = train_data[index].split(\",\")      \n",
    "    x1_name = data_dir + str_data[0]+\".npy\"\n",
    "    x2_name = data_dir + str_data[1]+\".npy\"\n",
    "    x3_name = data_dir + str_data[2]+\".npy\"\n",
    "    if os.path.isfile(x1_name) and os.path.isfile(x2_name) and os.path.isfile(x3_name): \n",
    "        return x1_name,x2_name,x3_name,index\n",
    "    else:\n",
    "        index += 6\n",
    "        return load_exits_file(train_data,index)\n",
    "    \n",
    "\n",
    "result_LSTM = {}\n",
    "result = []\n",
    "print(len(LSTM_testdata))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for key,token in enumerate(LSTM_testdata):\n",
    "        x1_name,x2_name,x3_name,exit_index = load_exits_file(LSTM_testdata,key)\n",
    "        x1 = torch.from_numpy(np.load(x1_name)).unsqueeze(0).unsqueeze(0).cuda()\n",
    "        x2 = torch.from_numpy(np.load(x2_name)).unsqueeze(0).unsqueeze(0).cuda()\n",
    "        x3 = torch.from_numpy(np.load(x3_name)).unsqueeze(0).unsqueeze(0).cuda()\n",
    "\n",
    "        predict_label = tripleNet_LSTM_model(x1,x2,x3).detach().cpu()\n",
    "        result_LSTM[token] = predict_label[0][0]\n",
    "        \n",
    "                \n",
    "#         if(key == 100):\n",
    "#             break\n",
    "\n",
    "print(len(result_LSTM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/media/data/cuixuange/ScrawlMusic/train_data_10part_normalizatin/\"\n",
    "def load_exits_file(train_data,index):\n",
    "    str_data = train_data[index].split(\",\")      \n",
    "    x1_name = data_dir + str_data[0]+\".npy\"\n",
    "    x2_name = data_dir + str_data[1]+\".npy\"\n",
    "    if os.path.isfile(x1_name) and os.path.isfile(x2_name):\n",
    "        return x1_name,x2_name,index\n",
    "    else:\n",
    "        index += 6\n",
    "        return load_exits_file(train_data,index)\n",
    "    \n",
    "\n",
    "result_SEN = {}\n",
    "result = []\n",
    "print(len(SEN_testdata))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for key,token in enumerate(SEN_testdata):\n",
    "        x1_name,x2_name,exit_index = load_exits_file(SEN_testdata,key)\n",
    "        X1 = torch.from_numpy(np.expand_dims(np.transpose(np.load(x1_name)),axis=2))\n",
    "        X2 = torch.from_numpy(np.expand_dims(np.transpose(np.load(x2_name)),axis=2))\n",
    "        X = torch.cat((X1,X2),dim=2)\n",
    "        X = X.unsqueeze(0)\n",
    "        X = X.unsqueeze(0) \n",
    "        x1 =torch.transpose((X[...,0]),2,3).cuda()\n",
    "        x2 =torch.transpose((X[...,1]),2,3).cuda()\n",
    "\n",
    "        predict_label = SENmodel(x1,x2).detach().cpu()\n",
    "        result_SEN[token] = predict_label[0][0]\n",
    "        \n",
    "#         if(key == 100):\n",
    "#             break\n",
    "\n",
    "print(len(result_SEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sympy.utilities.iterables import multiset_permutations\n",
    "\n",
    "def getMaxScoreInSong(index,songPart,modelName):\n",
    "    \"\"\"\n",
    "    input:  the index og the song, \n",
    "            the part(int) such as 3 or 4 ....or 10\n",
    "            which model to calculate\n",
    "    output: finalsorce, the sort which has max socre\n",
    "    \"\"\"\n",
    "    ps = [p for p in multiset_permutations(np.arange(songPart))]\n",
    "    maxSocre = 0.0\n",
    "    maxArrangement = []\n",
    "    for p in ps:\n",
    "        score = 0.0\n",
    "        if(modelName == \"TripletLSTM\"):\n",
    "            score = getLSTM_Score(index,p,songPart)\n",
    "        if(modelName == \"SEN\"):\n",
    "            score = getSEN_Score(index,p,songPart)\n",
    "        if maxSocre < score:\n",
    "            maxSocre = score\n",
    "            maxArrangement = p\n",
    "    return maxSocre,maxArrangement\n",
    "\n",
    "def isCorrectArrangement(listP):\n",
    "    \"\"\"\n",
    "    Judge is correct order，such as 1,2,3,4 is correct order\n",
    "    \"\"\"\n",
    "    for i in range(len(listP)-2):\n",
    "        if(listP[i+1] - listP[i] != 1):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def getSEN_Score(index,listPart,songPart):\n",
    "    \"\"\"\n",
    "    input: index of this song\n",
    "           listpart is current order which is waiting to calculate\n",
    "           songPart is the parts of this song  \n",
    "    output:current listPart socre\n",
    "    \"\"\"\n",
    "    token = []\n",
    "    score = 0.0\n",
    "    for i in range(0,songPart-1):\n",
    "        pair = \"song{}_{},song{}_{}\".format(index,listPart[i],index,listPart[i+1])\n",
    "        token.append(pair)\n",
    "    for i in token:\n",
    "        score += result_SEN[i]\n",
    "    return score\n",
    "\n",
    "def getLSTM_Score(index,listPart,songPart):\n",
    "    \"\"\"\n",
    "    input: index of this song\n",
    "           listpart is current order which is waiting to calculate\n",
    "           songPart is the parts of this song  \n",
    "    output:current listPart socre\n",
    "    \"\"\"\n",
    "    token = []\n",
    "    score = 0.0\n",
    "    for i in range(0,songPart-2):\n",
    "        triplet = \"song{}_{},song{}_{},song{}_{}\".format(index,listPart[i],index,listPart[i+1],index,listPart[i+2])\n",
    "        token.append(triplet)\n",
    "    for i in token:\n",
    "        score += result_LSTM[i]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelName=SEN\tPart=3\tAccuracy=0.67\ttime=0.05901932716369629\t\n",
      "modelName=TripletLSTM\tPart=3\tAccuracy=0.79\ttime=0.04198050498962402\t\n",
      "modelName=SEN\tPart=4\tAccuracy=0.43\ttime=0.08721303939819336\t\n",
      "modelName=TripletLSTM\tPart=4\tAccuracy=0.69\ttime=0.06798338890075684\t\n",
      "modelName=SEN\tPart=5\tAccuracy=0.32\ttime=0.25928759574890137\t\n",
      "modelName=TripletLSTM\tPart=5\tAccuracy=0.53\ttime=0.24993038177490234\t\n",
      "modelName=SEN\tPart=6\tAccuracy=0.17\ttime=1.1610150337219238\t\n",
      "modelName=TripletLSTM\tPart=6\tAccuracy=0.44\ttime=1.068131446838379\t\n",
      "modelName=SEN\tPart=7\tAccuracy=0.11\ttime=8.835685968399048\t\n",
      "modelName=TripletLSTM\tPart=7\tAccuracy=0.37\ttime=8.978431463241577\t\n",
      "modelName=SEN\tPart=8\tAccuracy=0.05\ttime=78.84110617637634\t\n",
      "modelName=TripletLSTM\tPart=8\tAccuracy=0.32\ttime=81.14716219902039\t\n",
      "modelName=SEN\tPart=9\tAccuracy=0.03\ttime=778.9665851593018\t\n",
      "modelName=TripletLSTM\tPart=9\tAccuracy=0.29\ttime=826.0625054836273\t\n",
      "modelName=SEN\tPart=10\tAccuracy=0.0\ttime=8769.560252666473\t\n",
      "modelName=TripletLSTM\tPart=10\tAccuracy=0.24\ttime=9303.699086427689\t\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "def calGA_Accuracy(songPart,modelName):\n",
    "    \"\"\"\n",
    "    songPart:  parts of song to order by\n",
    "    modelName: which model to use\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    count = 0\n",
    "    for index in range(sample):\n",
    "        _,arrange = getMaxScoreInSong(index,songPart,modelName)\n",
    "        if(isCorrectArrangement(arrange) == True):\n",
    "            count += 1     \n",
    "    end = time.time()\n",
    "    print(\"modelName={}\\tPart={}\\tAccuracy={}\\ttime={}\\t\".format(modelName,songPart,count/sample,end - start))\n",
    "\n",
    "for part in  songPart:\n",
    "    calGA_Accuracy(part,\"SEN\")\n",
    "    calGA_Accuracy(part,\"TripletLSTM\")\n",
    "#     if(part==4):\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n",
   "language": "python",
   "name": "cs231n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
